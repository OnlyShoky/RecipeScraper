{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched the sitemap index!\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sitemap(url):\n",
    "    \"\"\" Fetch the sitemap content from a URL \"\"\"\n",
    "    try:\n",
    "        # Send a GET request to the base page\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36\"}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        return response.text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def parse_sitemap(sitemap_xml):\n",
    "    \"\"\" Parse the XML sitemap to extract all URLs \"\"\"\n",
    "    urls = []\n",
    "    try:\n",
    "        root = ET.fromstring(sitemap_xml)\n",
    "        \n",
    "        # Define the namespace for handling the default namespace\n",
    "        namespaces = {\n",
    "            '': 'http://www.sitemaps.org/schemas/sitemap/0.9'  # Default namespace\n",
    "        }\n",
    "\n",
    "        # Find all <url> elements in the sitemap\n",
    "        for url in root.findall('.//url', namespaces):\n",
    "            loc = url.find('loc', namespaces)\n",
    "            if loc is not None:\n",
    "                # Extract the URL from the <loc> tag\n",
    "                urls.append(loc.text)\n",
    "\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing XML: {e}\")\n",
    "    \n",
    "    return urls\n",
    "\n",
    "def parse_sitemap_index(sitemap_xml):\n",
    "    \"\"\" Parse the XML sitemap index to extract URLs of individual sitemaps \"\"\"\n",
    "    urls = []\n",
    "    try:\n",
    "        # Parse the sitemap index XML\n",
    "        root = ET.fromstring(sitemap_xml)\n",
    "        \n",
    "        # Define the namespace to search for elements with the correct namespace\n",
    "        namespace = {'sitemap': 'http://www.sitemaps.org/schemas/sitemap/0.9'}\n",
    "\n",
    "        # Find all <loc> elements under <sitemap> tags\n",
    "        for sitemap in root.findall('.//sitemap:sitemap/sitemap:loc', namespace):\n",
    "            urls.append(sitemap.text)\n",
    "    except ET.ParseError as e:\n",
    "        print(f\"Error parsing XML: {e}\")\n",
    "    \n",
    "    return urls\n",
    "\n",
    "def save_urls(urls, filename):\n",
    "    \"\"\" Save the URLs to a file \"\"\"\n",
    "    with open(filename, 'w') as f:\n",
    "        for url in urls:\n",
    "            f.write(url + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sitemap index...\n",
      "Fetching https://preppykitchen.com/post-sitemap.xml...\n",
      "Parsing https://preppykitchen.com/post-sitemap.xml...\n",
      "Fetching https://preppykitchen.com/post-sitemap2.xml...\n",
      "Parsing https://preppykitchen.com/post-sitemap2.xml...\n",
      "Fetching https://preppykitchen.com/page-sitemap.xml...\n",
      "Parsing https://preppykitchen.com/page-sitemap.xml...\n",
      "Fetching https://preppykitchen.com/category-sitemap.xml...\n",
      "Parsing https://preppykitchen.com/category-sitemap.xml...\n",
      "Saving 0 URLs to 'recipes.txt'...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Fetch the sitemap index\n",
    "sitemap_url = \"https://preppykitchen.com/sitemap_index.xml\"\n",
    "\n",
    "\n",
    "sitemap_xml = fetch_sitemap(sitemap_url)\n",
    "\n",
    "\n",
    "if sitemap_xml:\n",
    "        # Parse the sitemap index to get individual sitemap URLs\n",
    "        print(\"Parsing sitemap index...\")\n",
    "        sitemaps = parse_sitemap_index(sitemap_xml)\n",
    "\n",
    "        all_urls = []\n",
    "        for sitemap_url in sitemaps:\n",
    "            print(f\"Fetching {sitemap_url}...\")\n",
    "            sitemap_xml = fetch_sitemap(sitemap_url)\n",
    "            if sitemap_xml:\n",
    "                print(f\"Parsing {sitemap_url}...\")\n",
    "                recipe_urls = parse_sitemap(sitemap_xml)\n",
    "                all_urls.extend(recipe_urls)\n",
    "                \n",
    "                # Save all URLs to a file\n",
    "        print(f\"Saving {len(all_urls)} URLs to 'recipes.txt'...\")\n",
    "        save_urls(all_urls, 'recipes.txt')\n",
    "        print(\"Done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sitemap index...\n",
      "Fetching https://preppykitchen.com/post-sitemap.xml...\n",
      "Parsing https://preppykitchen.com/post-sitemap.xml...\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "sitemap_url = \"https://preppykitchen.com/sitemap_index.xml\"\n",
    "sitemap_xml = fetch_sitemap(sitemap_url)\n",
    "if sitemap_xml:\n",
    "        # Parse the sitemap index to get individual sitemap URLs\n",
    "        print(\"Parsing sitemap index...\")\n",
    "        sitemaps = parse_sitemap_index(sitemap_xml)\n",
    "\n",
    "        all_urls = []\n",
    "        for sitemap_url in sitemaps:\n",
    "                print(f\"Fetching {sitemap_url}...\")\n",
    "                post_sitemap_xml = fetch_sitemap(sitemap_url)\n",
    "                if post_sitemap_xml:\n",
    "                        print(f\"Parsing {sitemap_url}...\")\n",
    "                        recipe_urls = parse_sitemap(post_sitemap_xml)\n",
    "                        print(recipe_urls)\n",
    "                        all_urls.extend(recipe_urls)\n",
    "                break\n",
    "                # Save all URLs to a file\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipe_urls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
